{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "0.15.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as tt\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import Vocab\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import wandb\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from vae_utils import get_vector_from_label, add_vector_to_images, morph_faces\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file = '/Users/parkermoesta/Library/Mobile Documents/com~apple~CloudDocs/Generative Models/LSTM/recipe_generator_LSTM/epirecipes.zip'\n",
    "extract_dir = '/Users/parkermoesta/Library/Mobile Documents/com~apple~CloudDocs/Generative Models/LSTM/recipe_generator_LSTM/data'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    # Extract all the contents of the zip file to the specified directory\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "with open(\"/Users/parkermoesta/Library/Mobile Documents/com~apple~CloudDocs/Generative Models/LSTM/recipe_generator_LSTM/data/full_format_recipes.json\") as json_data:\n",
    "    recipe_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset\n",
    "filtered_data = [\n",
    "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
    "    for x in recipe_data\n",
    "    if \"title\" in x\n",
    "    and x[\"title\"] is not None\n",
    "    and \"directions\" in x\n",
    "    and x[\"directions\"] is not None\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas | Chop enough parsley leaves to measure 1 tablespoon ; reserve . Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan , covered , 5 minutes . Meanwhile , sprinkle gelatin over water in a medium bowl and let soften 1 minute . Strain broth through a fine - mesh sieve into bowl with gelatin and stir to dissolve . Season with salt and pepper . Set bowl in an ice bath and cool to room temperature , stirring . Toss ham with reserved parsley and divide among jars . Pour gelatin on top and chill until set , at least 1 hour . Whisk together mayonnaise , mustard , vinegar , 1 / 4 teaspoon salt , and 1 / 4 teaspoon pepper in a large bowl . Stir in celery , cornichons , and potatoes . Pulse peas with marjoram , oil , 1 / 2 teaspoon pepper , and 1 / 4 teaspoon salt in a food processor to a coarse mash . Layer peas , then potato salad , over ham . '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the punctuation, to treat them as separate 'words'\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
    "    s = re.sub(\" +\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]\n",
    "text_data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data, tokenizer):\n",
    "        self.text_data = text_data\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.text_data[idx])\n",
    "        tokens = tokens[:200]  # Clip to maximum length of 200\n",
    "        return tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text_str in data_iter:\n",
    "        yield tokenizer(text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(text_data), max_tokens=VOCAB_SIZE, specials=['<pad>', '<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    stoi = vocab.get_stoi()\n",
    "    batch = [torch.tensor([stoi.get(token, stoi['<unk>']) for token in tokens]) for tokens in batch]\n",
    "    batch = pad_sequence(batch, batch_first=True, padding_value=stoi['<pad>'])\n",
    "    x = batch[:, :-1]\n",
    "    y = batch[:, 1:]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = TextDataset(text_data, tokenizer)\n",
    "text_loader = DataLoader(text_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x): recipe for doubles | in small bowl , stir together water , sugar , and yeast . let stand until foamy , about 5 or 6 minutes . in large bowl whisk together flour , salt , turmeric , cumin , and pepper . stir in yeast mixture , then add additional warm water , if needed , until mixture comes together into slightly firm dough . knead dough in bowl 2 minutes , then form into ball and cover with damp cloth . let dough rise in warm , draft - free place until doubled , about 1 hour . if using dried chickpeas , drain and add 6 cups fresh water . simmer until tender , about 1 hour . drain . if using canned chickpeas , drain and rinse well with cold water . in heavy skillet over moderately high heat , heat oil . add onion and sauté until translucent . add garlic and sauté 1 minute more . mix in curry powder and sauté 30 seconds , then add 1 / 4 cup water . stir in chickpeas , cover , and simmer 5 minutes . add 1 cup water and cumin . season\n",
      "Target (y): for doubles | in small bowl , stir together water , sugar , and yeast . let stand until foamy , about 5 or 6 minutes . in large bowl whisk together flour , salt , turmeric , cumin , and pepper . stir in yeast mixture , then add additional warm water , if needed , until mixture comes together into slightly firm dough . knead dough in bowl 2 minutes , then form into ball and cover with damp cloth . let dough rise in warm , draft - free place until doubled , about 1 hour . if using dried chickpeas , drain and add 6 cups fresh water . simmer until tender , about 1 hour . drain . if using canned chickpeas , drain and rinse well with cold water . in heavy skillet over moderately high heat , heat oil . add onion and sauté until translucent . add garlic and sauté 1 minute more . mix in curry powder and sauté 30 seconds , then add 1 / 4 cup water . stir in chickpeas , cover , and simmer 5 minutes . add 1 cup water and cumin . season with\n",
      "---\n",
      "Input (x): recipe for poached eggs with mushroom , tamarillo , and sage | bring 2 water to a boil in a large saucepan reduce heat to a gentle simmer and add vinegar . crack an egg into a small bowl gently slide egg into water . repeat with remaining eggs , waiting until whites start to set before adding the next . poach until whites are set and yolks are still runny , about 2 minutes . using a slotted spoon , transfer eggs as they are done to paper towels . heat 2 tablespoons butter in a large skillet over medium - high . add half of both mushrooms season with kosher salt and pepper . cook , tossing occasionally , until mushrooms are tender and browned , about 5 minutes . transfer to a plate . repeat with remaining mushrooms and another 2 tablespoons butter transfer to same plate . drizzle with 1 tablespoon lemon juice . heat remaining 2 tablespoons butter in same skillet over medium - high cook sage , shaking skillet , until fragrant and crisp , about 2 minutes . transfer to paper towels with a slotted spoon . reserve skillet . divide tamarillo\n",
      "Target (y): for poached eggs with mushroom , tamarillo , and sage | bring 2 water to a boil in a large saucepan reduce heat to a gentle simmer and add vinegar . crack an egg into a small bowl gently slide egg into water . repeat with remaining eggs , waiting until whites start to set before adding the next . poach until whites are set and yolks are still runny , about 2 minutes . using a slotted spoon , transfer eggs as they are done to paper towels . heat 2 tablespoons butter in a large skillet over medium - high . add half of both mushrooms season with kosher salt and pepper . cook , tossing occasionally , until mushrooms are tender and browned , about 5 minutes . transfer to a plate . repeat with remaining mushrooms and another 2 tablespoons butter transfer to same plate . drizzle with 1 tablespoon lemon juice . heat remaining 2 tablespoons butter in same skillet over medium - high cook sage , shaking skillet , until fragrant and crisp , about 2 minutes . transfer to paper towels with a slotted spoon . reserve skillet . divide tamarillo slices\n",
      "---\n",
      "Input (x): recipe for mango gazpacho with pickled shrimp | combine first 6 ingredients in medium saucepan . cover bring to boil . remove from heat . stir in cilantro , onions , and jalapeño . transfer to glass jar and add shrimp . chill uncovered until cold , then cover and chill overnight . purée first 10 ingredients in blender . chill 2 hours . do ahead can be made 8 hours ahead . keep refrigerated . ladle soup into 4 bowls top each with 3 shrimp . garnish with cilantro . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target (y): for mango gazpacho with pickled shrimp | combine first 6 ingredients in medium saucepan . cover bring to boil . remove from heat . stir in cilantro , onions , and jalapeño . transfer to glass jar and add shrimp . chill uncovered until cold , then cover and chill overnight . purée first 10 ingredients in blender . chill 2 hours . do ahead can be made 8 hours ahead . keep refrigerated . ladle soup into 4 bowls top each with 3 shrimp . garnish with cilantro . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "---\n",
      "Input (x): recipe for southern cross | pour wine into a heavy saucepan and add all ingredients except the raisins and water . heat gently . meanwhile , put the raisins into a small saucepan with the water and slowly bring to a boil . add water with raisins to the hot wine mixture and pour into a metal punch bowl . serve in 4 - ounce glasses . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Target (y): for southern cross | pour wine into a heavy saucepan and add all ingredients except the raisins and water . heat gently . meanwhile , put the raisins into a small saucepan with the water and slowly bring to a boil . add water with raisins to the hot wine mixture and pour into a metal punch bowl . serve in 4 - ounce glasses . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "---\n",
      "Input (x): recipe for toasted - hazelnut cake | preheat oven to 350°f . and grease a 9 - inch springform pan . rub hot toasted nuts in a kitchen towel to remove some of skins , then cool completely . pulse nuts , cake meal , and 1 / 4 cup sugar in a food processor until nuts are very finely chopped , being careful not to process to a paste . beat yolks and 1 / 2 cup sugar in a large bowl with an electric mixer on high speed until pale and very thick . stir in zest . beat whites with salt in another bowl with cleaned beaters on high speed until soft peaks form . gradually beat in remaining 1 / 4 cup sugar and beat until whites just hold stiff , glossy peaks . in 3 batches , alternately fold nut mixture and whites into yolk mixture . spoon batter into pan and smooth top . bake cake in middle of oven until golden and a tester comes out clean , about 35 minutes . cool in pan on a rack 3 minutes , then loosen edge with a knife and remove side of pan\n",
      "Target (y): for toasted - hazelnut cake | preheat oven to 350°f . and grease a 9 - inch springform pan . rub hot toasted nuts in a kitchen towel to remove some of skins , then cool completely . pulse nuts , cake meal , and 1 / 4 cup sugar in a food processor until nuts are very finely chopped , being careful not to process to a paste . beat yolks and 1 / 2 cup sugar in a large bowl with an electric mixer on high speed until pale and very thick . stir in zest . beat whites with salt in another bowl with cleaned beaters on high speed until soft peaks form . gradually beat in remaining 1 / 4 cup sugar and beat until whites just hold stiff , glossy peaks . in 3 batches , alternately fold nut mixture and whites into yolk mixture . spoon batter into pan and smooth top . bake cake in middle of oven until golden and a tester comes out clean , about 35 minutes . cool in pan on a rack 3 minutes , then loosen edge with a knife and remove side of pan .\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch from the DataLoader\n",
    "for x, y in text_loader:\n",
    "    break\n",
    "\n",
    "# Convert indices back to tokens\n",
    "def indices_to_tokens(indices):\n",
    "    itos = vocab.get_itos()\n",
    "    return ' '.join([itos[index] for index in indices])\n",
    "\n",
    "# Print the first few sentences in the batch\n",
    "for i in range(5):  # Change this number to print more or fewer sentences\n",
    "    print(\"Input (x):\", indices_to_tokens(x[i]))\n",
    "    print(\"Target (y):\", indices_to_tokens(y[i]))\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return self.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (embedding): Embedding(10000, 100)\n",
      "  (lstm): LSTM(100, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=10000, bias=True)\n",
      "  (log_softmax): LogSoftmax(dim=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, N_UNITS).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mparkermoesta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/parkermoesta/Generative_models/Gen_Models_Master/Generative_models/Autoregressive Models/LSTM/wandb/run-20230715_142437-wiy9j0gj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2/runs/wiy9j0gj' target=\"_blank\">breezy-terrain-1</a></strong> to <a href='https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2' target=\"_blank\">https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2/runs/wiy9j0gj' target=\"_blank\">https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2/runs/wiy9j0gj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/parkermoesta/LTSM%20-%20Recipe%20Generation%20-%20fixed%20gen_v2/runs/wiy9j0gj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb6c32d51c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"LTSM - Recipe Generation - fixed gen_v2\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"architecture\": \"RNN-LSTM\",\n",
    "    \"dataset\": \"Recipes\",\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 128,\n",
    "    \"latent_dim\": 100,\n",
    "    \"BatchNorm\": True,\n",
    "    \"Dropout\": True,\n",
    "    \"Normalize\": True,\n",
    "    \"Gradient Penalty\": False,\n",
    "    \"loss function\": \"NLLLoss\",\n",
    "    \"activation\": \"LeakyReLU\",\n",
    "    \"notes\": \"Inc learning on gen, dec on disc. incerasing gradient penalty to 12\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Define the number of epochs\n",
    "EPOCHS = 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, vocab, top_k=10):\n",
    "        self.vocab = vocab\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def sample_from(self, logits, temperature):\n",
    "        probs = F.softmax(logits / temperature, dim=-1).cpu().numpy()\n",
    "        return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    def generate(self, model, device, start_prompt, max_tokens, temperature):\n",
    "        model.eval()\n",
    "\n",
    "        tokens = [self.vocab.get_stoi()[token] for token in start_prompt.split()]\n",
    "        tokens = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_tokens):\n",
    "                output = model(tokens)\n",
    "                next_token_logits = output[0, -1, :]\n",
    "                next_token = self.sample_from(next_token_logits, temperature)\n",
    "                tokens = torch.cat([tokens, torch.LongTensor([[next_token]]).to(device)], dim=1)\n",
    "\n",
    "        generated_text = ' '.join(self.vocab.get_itos()[token] for token in tokens[0])\n",
    "        return generated_text\n",
    "\n",
    "\n",
    "def train(model, optimizer, text_loader, device, start_epoch, num_epochs, checkpoint_path=None, log_wandb=True):\n",
    "    # Load the checkpoint if it exists\n",
    "    if checkpoint_path is not None and log_wandb:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print('Loaded model from checkpoint')\n",
    "        \n",
    "    # Define the loss function\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(start_epoch, num_epochs)):\n",
    "        model.train()  # Ensure the model is in training mode\n",
    "        for i, (x, y) in enumerate(text_loader):\n",
    "            # Move the data to the device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(y_pred.reshape(-1, VOCAB_SIZE), y.reshape(-1))\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Compute gradient norm and clip gradients\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss every 100 batches\n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item()}')\n",
    "\n",
    "            # Log loss and perplexity to Weights & Biases\n",
    "            if log_wandb:\n",
    "                wandb.log({\n",
    "                    \"Epoch\": epoch,\n",
    "                    \"Batch\": i,\n",
    "                    \"Loss\": loss.item(),\n",
    "                    \"Perplexity\": torch.exp(loss).item(),\n",
    "                    \"Gradient Norm\": grad_norm.item()\n",
    "                })\n",
    "\n",
    "        text_generator = TextGenerator(vocab)\n",
    "        generated_text = text_generator.generate(model, device, \"recipe for\", max_tokens=100, temperature=1.0)\n",
    "        print(generated_text)\n",
    "        if log_wandb:\n",
    "            wandb.log({\"Generated Text\": wandb.Html(f\"<pre>{generated_text}</pre>\", inject=False)})\n",
    "\n",
    "        # Save a checkpoint after each epoch\n",
    "        if log_wandb:\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch\n",
    "            }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "            # log the checkpoint to wandb\n",
    "            wandb.save(f'checkpoint_epoch_{epoch}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch 0, Loss: 1.3963435888290405\n",
      "Epoch 50, Batch 100, Loss: 1.3973511457443237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:41<33:29, 41.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for roast quail with haricots verts and eggplant with savoy tomatoes | 1 . prepare a gas grill with grill for grilling . grill the bell peppers for 1 - 3 or 3 or a flame , covered with a weighted and ensure hot yellow to coat the fish well with the marinade , for 2 - oz . 2 inch brown oil marinade inside a large cast iron skillet , then reduce temperature to 200°f . oil the grill pan or heat off 350°f . the chimichurri tofu aside . starting from the pans and boil for a minute or\n",
      "Epoch 51, Batch 0, Loss: 1.4483486413955688\n",
      "Epoch 51, Batch 100, Loss: 1.507794976234436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:20<32:11, 40.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for wakame beignets tostada with lemon cream | in a large pitcher place mango mixture in 2 - quart terrine or coffee bottle , making sure that enjoy . strain . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Epoch 52, Batch 0, Loss: 1.4285203218460083\n",
      "Epoch 52, Batch 100, Loss: 1.4886155128479004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [02:00<31:20, 40.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for zucchini seed and corn muffins | preheat oven to 375°f . cut away dark flesh of white core but about 1 slice into 1 - inch pieces . place 1 tablespoon filling in bottom of shell . carefully remove paper from oranges , leaving deep skin side in same manner . in butter 3 - to 4 top with 4 - inch slices , making striped line each baking sheets with parchment paper . mound flour in top of double layer of large rimmed baking sheet . using electric mixer , beat 1 1 / 2 cups cornmeal and cinnamon\n",
      "Epoch 53, Batch 0, Loss: 1.333232045173645\n",
      "Epoch 53, Batch 100, Loss: 1.5901602506637573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:39<30:18, 39.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe for tortellini in chicken stock | stir together water , vinegar , garlic , ginger , and 2 cups water . cover and refrigerate slightly several hours for 15 minutes . place ground cloves on a work surface of plastic wrap . 3 . for a charcoal grill , cook an coals on a gas grill , turning often on bottom of grill and grate or place a bit before using a heavy cleaver or small amount of dough from water ( don ' t worry if some part of briquettes ) . grill corn , and thread on a top\n",
      "Epoch 54, Batch 0, Loss: 1.3600329160690308\n",
      "Epoch 54, Batch 100, Loss: 1.4815459251403809\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 50\n",
    "checkpoint_path = f'checkpoint_epoch_{start_epoch - 1}.pth'\n",
    "\n",
    "train(model, optimizer, text_loader, device, start_epoch=50, num_epochs=100, checkpoint_path=checkpoint_path, log_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from checkpoint\n"
     ]
    }
   ],
   "source": [
    "# loading model from checkpoint\n",
    "checkpoint_path = '/Users/parkermoesta/Library/Mobile Documents/com~apple~CloudDocs/Generative Models/LSTM/recipe_generator_LSTM/checkpoint_epoch_99.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "print('Loaded model from checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text: recipe for roasted vegetables | chop 1 / 2 cup onion and reserve for another use . place garlic in a large , heavy - bottomed saucepan over medium - high heat . add onions and sauté until tender , about 5 minutes . add garlic and stir - fry until water evaporates , about 2 minutes . add wine and bring to boil . reduce heat to medium and simmer , covered , until vegetables are tender , about 20 minutes . uncover and cook until liquid is reduced by half , about 30 minutes . add wine and boil until reduced by half , about 1\n"
     ]
    }
   ],
   "source": [
    "text_generator = TextGenerator(vocab=vocab, top_k=10)\n",
    "generated_text = text_generator.generate(model=model, device=device, start_prompt=\"recipe for roasted vegetables | chop 1 /\", max_tokens=100, temperature=0.5)\n",
    "\n",
    "print(f\"\\nGenerated Text: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
